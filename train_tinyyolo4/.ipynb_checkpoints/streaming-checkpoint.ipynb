{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#import modules\n",
    "\n",
    "import vrep\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import os\n",
    "from math import pi, cos, sin\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ikpy.chain import Chain\n",
    "from ikpy.link import OriginLink, URDFLink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrep.simxFinish(-1)\n",
    "\n",
    "clientID = vrep.simxStart('127.0.0.1', 19999, True, True, 5000, 5)\n",
    "\n",
    "WAIT = vrep.simx_opmode_oneshot_wait\n",
    "ONESHOT = vrep.simx_opmode_oneshot\n",
    "STREAMING = vrep.simx_opmode_streaming\n",
    "BUFFER = vrep.simx_opmode_buffer\n",
    "BLOCKING = vrep.simx_opmode_blocking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotatin about x axis\n",
    "def R_x(angle):\n",
    "    \n",
    "    angle = np.radians(angle)\n",
    "    R_x = sp.Matrix([[1,    0,             0,              0],\n",
    "                     [0,    sp.cos(angle), -sp.sin(angle), 0],\n",
    "                     [0,    sp.sin(angle), sp.cos(angle),  0],\n",
    "                     [0,    0,             0,              1]])\n",
    "    return R_x\n",
    "\n",
    "# Rotatin about y axis\n",
    "def R_y(angle):\n",
    "    \n",
    "    angle = np.radians(angle)\n",
    "    R_y = sp.Matrix([[sp.cos(angle),  0,    sp.sin(angle), 0],\n",
    "                     [0,              1,    0,             0],\n",
    "                     [-sp.sin(angle), 0,    sp.cos(angle), 0],\n",
    "                     [0,              0,    0,             1]])\n",
    "    return R_y\n",
    "\n",
    "# Rotatin about z axis\n",
    "def R_z(angle):\n",
    "    \n",
    "    angle = np.radians(angle)\n",
    "    R_z = sp.Matrix([[sp.cos(angle), -sp.sin(angle),  0,   0],\n",
    "                     [sp.sin(angle), sp.cos(angle),   0,   0],\n",
    "                     [0,             0,               1,   0],\n",
    "                     [0,             0,               0,   1]])\n",
    "    return R_z\n",
    "\n",
    "# Trans to (x,y,z)\n",
    "def Trans(x,y,z):\n",
    "    \n",
    "    Trans = sp.Matrix([[1, 0,  0, x],\n",
    "                       [0, 1,  0, y],\n",
    "                       [0, 0,  1, z],\n",
    "                       [0, 0,  0, 1]])\n",
    "    return Trans\n",
    "\n",
    "\n",
    "\n",
    "# Get EndEffector position\n",
    "def EE_pos(th1, th2, th3, th4):\n",
    "    d0 = 86\n",
    "    d1 = 43\n",
    "    d2 = 107 \n",
    "    d3 = 106\n",
    "    d4 = 89\n",
    "\n",
    "    T_total = Trans(0,0,d0)*R_z(th1)*Trans(0,0,d1)*R_y(th2)*Trans(0,0,d2)*R_y(th3)*Trans(0,0,d3)*R_y(th4)*Trans(0,0,d4)\n",
    "    return T_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Kinematics model\n",
    "rbtarm = Chain(name='rbtarm', links=[\n",
    "    OriginLink(),\n",
    "    URDFLink(\n",
    "      name=\"base\",\n",
    "      translation_vector=[0, 0, 86],\n",
    "      orientation=[0, 0, 0],\n",
    "      rotation=[0, 0, 0],\n",
    "    ),\n",
    "    URDFLink(\n",
    "      name=\"link1\",\n",
    "      translation_vector=[0, 0, 43],\n",
    "      orientation=[0, 0, 0],\n",
    "      rotation=[0, 0, 1],\n",
    "    ),\n",
    "    URDFLink(\n",
    "      name=\"link12\",\n",
    "      translation_vector=[0, 0, 0],\n",
    "      orientation=[0, 0, 0],\n",
    "      rotation=[0, 1, 0],\n",
    "    ),\n",
    "    URDFLink(\n",
    "      name=\"link2\",\n",
    "      translation_vector=[0, 0, 107],\n",
    "      orientation=[0, 0, 0],\n",
    "      rotation=[0, 1, 0],\n",
    "    ),\n",
    "    URDFLink(\n",
    "      name=\"link3\",\n",
    "      translation_vector=[0, 0, 106],\n",
    "      orientation=[0, 0, 0],\n",
    "      rotation=[0, 1, 0],\n",
    "    ),\n",
    "    URDFLink(\n",
    "      name=\"gripper\",\n",
    "      translation_vector=[0, 0, 89],\n",
    "      orientation=[0, 0, 0],\n",
    "      rotation=[0, 1, 0],\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "labelsPath = os.path.join(\"./darknet/data/\",\"yolo.names\")\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "LABELS\n",
    "\n",
    "weightsPath = os.path.join(\"/home/inwook/test/darknet/backup/yolov3_custom_train_1000.weights\")\n",
    "configPath = os.path.join(\"/home/inwook/test/darknet/cfg/yolov3_custom_test.cfg\")\n",
    "\n",
    "# Loading the neural network\n",
    "net = cv2.dnn.readNetFromDarknet(configPath,weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    \n",
    "    # initialize a list of colors to represent each possible class label\n",
    "    np.random.seed(42)\n",
    "    COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    # determine only the \"ouput\" layers name which we need from YOLO\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    # construct a blob from the input image and then perform a forward pass of the YOLO object detector, \n",
    "    # giving us our bounding boxes and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (608, 608), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    threshold = 0.2\n",
    "    \n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability) of\n",
    "            # the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter out weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            # confidence type=float, default=0.5\n",
    "            if confidence > threshold:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates, confidences,\n",
    "                # and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, threshold, 0.1)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # draw a bounding box rectangle and label on the image\n",
    "            color = (255,0,0)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            text = \"{}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "            cv2.putText(image, text, (x +15, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, color, 2)\n",
    "            \n",
    "            alpha = x + w/2\n",
    "            beta = y + h/2\n",
    "            print(text+ \": \" + str(alpha), str(beta))\n",
    "            \n",
    "            target_position = [-25+beta, -304+alpha,  150]\n",
    "            print(target_position)\n",
    "            th1 = (rbtarm.inverse_kinematics(target_position).round(3)[2])\n",
    "            th2 = (rbtarm.inverse_kinematics(target_position).round(3)[3])\n",
    "            th3 = (rbtarm.inverse_kinematics(target_position).round(3)[4])\n",
    "            th4 = (rbtarm.inverse_kinematics(target_position).round(3)[5])\n",
    "            print(th1, th2, th3, th4)\n",
    "            \n",
    "            \n",
    "            print(\"x, y, z coordinate = \",EE_pos(np.degrees(th1),np.degrees(th2),np.degrees(th3),np.degrees(th4))[0:3,3])\n",
    "#             [th1, th2, th3, th4] = [th1*pi/180, th2*pi/180, th3*pi/180, th4*pi/180 ]\n",
    "        \n",
    "            move_joint1(th1)\n",
    "            move_joint2(th2)\n",
    "            move_joint3(th3)\n",
    "            move_joint4(th4)\n",
    "            \n",
    "            \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remote API server\n",
      "Getting first image\n",
      "angle of joints 1~40 45 45 45\n",
      "x, y, z coordinate =  Matrix([[244.592929112563], [0], [141.727922061358]])\n",
      "angle of joints 1~40 50 50 50 \n",
      "x, y, z coordinate =  Matrix([[230.856377233025], [0], [102.295306466950]])\n",
      "angle of joints 1~40 50 50 30 \n",
      "x, y, z coordinate =  Matrix([[254.534332670614], [0], [122.163470141663]])\n",
      "angle of joints 1~40 60 50 30 \n",
      "x, y, z coordinate =  Matrix([[249.480233270343], [0], [78.0679093698901]])\n",
      "angle of joints 1~40 65 50 30 \n",
      "x, y, z coordinate =  Matrix([[244.091861474050], [0], [56.5180863200204]])\n",
      "angle of joints 1~40 70 50 30 \n",
      "x, y, z coordinate =  Matrix([[236.845803225243], [0], [35.5198943990316]])\n"
     ]
    }
   ],
   "source": [
    "if clientID!=-1:\n",
    "    print('Connected to remote API server')\n",
    "    \n",
    "\n",
    "    res, v1 = vrep.simxGetObjectHandle(clientID, 'Vision_sensor0', WAIT)# (clientID, NAME, MODE)\n",
    "    \n",
    "    print('Getting first image')\n",
    "    rc, resolution, image = vrep.simxGetVisionSensorImage(clientID, v1, 0, STREAMING)\n",
    "    # returncode, (x,y), imagedata\n",
    "\n",
    "    rc,joint1_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_joint1\",WAIT)\n",
    "    rc,joint1 = vrep.simxGetJointPosition(clientID,joint1_handle,STREAMING)\n",
    "  \n",
    "    rc,joint2_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_joint2\",WAIT)\n",
    "    rc,joint2 = vrep.simxGetJointPosition(clientID,joint2_handle,STREAMING)\n",
    "    \n",
    "    rc,joint3_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_joint3\",WAIT)\n",
    "    rc,joint3 = vrep.simxGetJointPosition(clientID,joint3_handle,STREAMING)\n",
    "    \n",
    "    rc,joint4_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_joint4\",WAIT)\n",
    "    rc,joint4 = vrep.simxGetJointPosition(clientID,joint4_handle,STREAMING)\n",
    "    \n",
    "    rc,gripper_center_joint_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_gripperCenter_joint\",BLOCKING)\n",
    "    ret,center_force=vrep.simxGetJointForce(clientID,gripper_center_joint_handle,STREAMING)\n",
    "    ret,gripper_center_joint = vrep.simxGetJointPosition(clientID,gripper_center_joint_handle,STREAMING)\n",
    "    \n",
    "    \n",
    "    rc,gripper_close_joint_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_gripperClose_joint\",BLOCKING)\n",
    "    ret,close_force=vrep.simxGetJointForce(clientID,gripper_close_joint_handle,STREAMING)\n",
    "    ret,gripper_close_joint = vrep.simxGetJointPosition(clientID,gripper_close_joint_handle,STREAMING)\n",
    "    \n",
    "    # Print joint's angle by deg\n",
    "    def get_joint_angle():\n",
    "        rc,joint1 = vrep.simxGetJointPosition(clientID,joint1_handle,STREAMING)\n",
    "        rc,joint2 = vrep.simxGetJointPosition(clientID,joint2_handle,STREAMING)\n",
    "        rc,joint3 = vrep.simxGetJointPosition(clientID,joint3_handle,STREAMING)\n",
    "        rc,joint4 = vrep.simxGetJointPosition(clientID,joint4_handle,STREAMING)\n",
    "        joint_angle = [joint1*180/pi, joint2*180/pi, joint3*180/pi, joint4*180/pi]\n",
    "        print(np.round(joint_angle,3))\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # move joint1 to th1\n",
    "    def move_joint1(th1):\n",
    "        while(True):\n",
    "            rc,joint1 = vrep.simxGetJointPosition(clientID,joint1_handle,STREAMING)\n",
    "            v1 = (th1 - joint1)/10\n",
    "            v1 = np.sign(v1)*max(v1,0.1)\n",
    "            err = vrep.simxSetJointTargetVelocity(clientID,joint1_handle,v1,STREAMING)\n",
    "            if (abs(joint1-th1)<0.01):\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,joint1_handle,0,STREAMING)\n",
    "                break\n",
    "            \n",
    "    # move joint2 to th2        \n",
    "    def move_joint2(th2):\n",
    "        while(True):\n",
    "            rc,joint2 = vrep.simxGetJointPosition(clientID,joint2_handle,STREAMING)\n",
    "            v2 = (th2 - joint2)/10\n",
    "            v2 = np.sign(v2)*max(v2,0.1)\n",
    "            err = vrep.simxSetJointTargetVelocity(clientID,joint2_handle,v2,STREAMING)\n",
    "            if (abs(joint2-th2)<0.01):\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,joint2_handle,0,STREAMING)\n",
    "#                 print(\"joint2 ok\")\n",
    "                break\n",
    "                \n",
    "    # move joint3 to th3            \n",
    "    def move_joint3(th3):\n",
    "        while(True):\n",
    "            rc,joint3 = vrep.simxGetJointPosition(clientID,joint3_handle,STREAMING)\n",
    "            v3 = (th3 - joint3)/10\n",
    "            v3 = np.sign(v3)*max(v3,0.1)\n",
    "            err = vrep.simxSetJointTargetVelocity(clientID,joint3_handle,v3,STREAMING)\n",
    "            if (abs(joint3-th3)<0.01):\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,joint3_handle,0,STREAMING)\n",
    "#                 print(\"joint3 ok\")\n",
    "                break\n",
    "                \n",
    "    # move joint4 to th4            \n",
    "    def move_joint4(th4):\n",
    "        while(True):\n",
    "            rc,joint4 = vrep.simxGetJointPosition(clientID,joint4_handle,STREAMING)\n",
    "            v4 = (th4 - joint4)/10\n",
    "            v4 = np.sign(v4)*max(v4,0.1)\n",
    "            err = vrep.simxSetJointTargetVelocity(clientID,joint4_handle,v4,STREAMING)\n",
    "            if (abs(joint4-th4)<0.01):\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,joint4_handle,0,STREAMING)\n",
    "#                 print(\"joint4 ok\")\n",
    "                break\n",
    "            \n",
    "    # Print joint's global coordinates    \n",
    "    def get_pos():\n",
    "        joint_pos = [None]*5\n",
    "        for i in range(0,4):\n",
    "            rc,joint_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_joint\"+str(i+1),WAIT)\n",
    "            err,joint_pos[i] = vrep.simxGetObjectPosition(clientID, joint_handle, -1, STREAMING)\n",
    "        rc,gripper_center_joint_handle = vrep.simxGetObjectHandle(clientID,\"PhantomXPincher_gripperCenter_joint\",BLOCKING)\n",
    "        err,joint_pos[4] = vrep.simxGetObjectPosition(clientID, gripper_center_joint_handle, -1, STREAMING)\n",
    "        print(np.round(joint_pos,3))\n",
    "        \n",
    "    # Go to initial position    \n",
    "    \n",
    "    def init_pos():\n",
    "        move_joint1(0)\n",
    "        move_joint2(0)\n",
    "        move_joint3(pi/2)\n",
    "        move_joint4(pi/4)\n",
    "        \n",
    "    def display_img(img,cmap=None):\n",
    "        fig = plt.figure(figsize = (12,12))\n",
    "        plt.axis(False)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.imshow(img,cmap)\n",
    "    \n",
    "    def get_image():\n",
    "        err, resolution, image = vrep.simxGetVisionSensorImage(clientID, v1, 0, BUFFER)# following streaming\n",
    "        img = np.array(image,dtype=np.uint8)\n",
    "        img.resize([resolution[1],resolution[0],3])\n",
    "        img = cv2.flip(img,0)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = predict(img)\n",
    "        cv2.imshow('image',img)  \n",
    "        \n",
    "            \n",
    "    # Go to (th1, th2, th3, th4)        \n",
    "    def move_angle():\n",
    "        th1, th2, th3, th4 = map(float,input('angle of joints 1~4').split())\n",
    "\n",
    "#         # predict coordinates to IK target position\n",
    "        \n",
    "#         target_position = [304-alpha, -25+beta, 100]\n",
    "    \n",
    "#         th1 = rbtarm.inverse_kinematics(target_position).round(3)[2]\n",
    "#         th2 = rbtarm.inverse_kinematics(target_position).round(3)[3]\n",
    "#         th3 = rbtarm.inverse_kinematics(target_position).round(3)[4]\n",
    "#         th4 = rbtarm.inverse_kinematics(target_position).round(3)[5]\n",
    "    \n",
    "            \n",
    "        print(\"x, y, z coordinate = \",EE_pos(th1,th2,th3,th4)[0:3,3])\n",
    "        [th1, th2, th3, th4] = [th1*pi/180, th2*pi/180, th3*pi/180, th4*pi/180 ]\n",
    "        \n",
    "        move_joint1(th1)\n",
    "        move_joint2(th2)\n",
    "        move_joint3(th3)\n",
    "        move_joint4(th4)\n",
    "        \n",
    "        \n",
    "    def grab():\n",
    "        while(True):\n",
    "            ret,center_force=vrep.simxGetJointForce(clientID,gripper_center_joint_handle,BUFFER)\n",
    "            ret,close_force=vrep.simxGetJointForce(clientID,gripper_close_joint_handle,BUFFER)\n",
    "            ret,gripper_close_joint = vrep.simxGetJointPosition(clientID,gripper_close_joint_handle,STREAMING)\n",
    "            ret,gripper_center_joint = vrep.simxGetJointPosition(clientID,gripper_center_joint_handle,STREAMING)\n",
    "            print(center_force, close_force)\n",
    "\n",
    "            if (close_force>4):\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,gripper_center_joint_handle,0,STREAMING)\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,gripper_close_joint_handle,0,STREAMING)\n",
    "                err = vrep.simxSetJointTargetPosition(clientID,gripper_center_joint,0.01,STREAMING)\n",
    "                err = vrep.simxSetJointTargetPosition(clientID,gripper_close_joint,0.02,STREAMING)\n",
    "                print(\"gripper closed\")\n",
    "                breaker = True\n",
    "                break\n",
    "#             if (gripper_close_joint<0.001):\n",
    "#                 init_grab()\n",
    "            err = vrep.simxSetJointTargetVelocity(clientID,gripper_center_joint_handle,-0.005,STREAMING)\n",
    "            err = vrep.simxSetJointTargetVelocity(clientID,gripper_close_joint_handle,-0.010,STREAMING)\n",
    "            \n",
    "    def init_grab():\n",
    "        while(True):\n",
    "            breaker = False\n",
    "            ret,gripper_center_joint = vrep.simxGetJointPosition(clientID,gripper_center_joint_handle,STREAMING)\n",
    "            ret,gripper_close_joint = vrep.simxGetJointPosition(clientID,gripper_close_joint_handle,STREAMING)\n",
    "#             print(gripper_center_joint,gripper_close_joint)\n",
    "\n",
    "            if (gripper_close_joint<0.001):\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,gripper_center_joint_handle,0,STREAMING)\n",
    "                err = vrep.simxSetJointTargetVelocity(clientID,gripper_close_joint_handle,0,STREAMING)\n",
    "                print(\"gripper closed\")\n",
    "                breaker = True\n",
    "                break\n",
    "#             if ():\n",
    "#             err = vrep.simxSetJointTargetVelocity(clientID,gripper_center_joint_handle,0.005,STREAMING)\n",
    "#             err = vrep.simxSetJointTargetVelocity(clientID,gripper_close_joint_handle,0.010,STREAMING)\n",
    "\n",
    "    def command():\n",
    "        command = str(input('type command'))\n",
    "        if (command == grab):\n",
    "            print(grab)\n",
    "            grab()\n",
    "            \n",
    "    init_pos()\n",
    "    \n",
    "    \n",
    "        \n",
    "    while (vrep.simxGetConnectionId(clientID) != -1):\n",
    "        \n",
    "        \n",
    "#             get_joint_angle()\n",
    "#         get_image()\n",
    "        move_angle()\n",
    "#             command()\n",
    "#             init_grab()\n",
    "#           get_pos()\n",
    "        \n",
    "                \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "else:\n",
    "  print(\"Failed to connect to remote API Server\")\n",
    "  vrep.simxFinish(clientID)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
